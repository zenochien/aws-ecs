[
{
	"uri": "/2-prerequiste/1-create-vpc/",
	"title": "Create a VPC",
	"tags": [],
	"description": "",
	"content": "Creating a VPC, Subnets, and VPC Resources Using the Console Use the following procedure to create a VPC along with additional VPC resources you need to run your application, such as subnets, route tables, Internet gateways, and NAT gateways. For VPC configuration examples, refer to the VPC Examples.\n Open the Amazon VPC console here.   On the VPC dashboard, choose Create VPC.\n  For Resources to create, choose VPC and more.\n   Keep the Name tag auto-generation option selected to create Name tags for VPC resources, or deselect it to provide your own Name tags for VPC resources.\n  For the IPv4 CIDR block range, enter an IPv4 address range for your VPC. A VPC must have an IPv4 address range.\n  (Optional) To support IPv6 traffic, select IPv6 CIDR block, an IPv6 range provided by Amazon.\n  Choose a Tenancy option. This option determines whether the EC2 instances you launch into the VPC will run on hardware shared with other AWS accounts or on dedicated hardware for your use. If you select VPC Tenancy as Default, EC2 instances launched into this VPC will use the Tenancy attribute you specify when launching instances - See more details in the Amazon EC2 User Guide for Linux Instances. If you select VPC Tenancy as Dedicated, the instances will always run as Dedicated Instances on hardware dedicated to you. If you\u0026rsquo;re using AWS Outposts, your Outpost must have private connectivity; you must use the default Tenancy.\n  For Number of Availability Zones (AZs), we recommend providing subnets in at least two Availability Zones for a production environment. To select AZs for your subnets, expand Customize AZs. Otherwise, let AWS choose for you.\n   To configure your subnets, select values for Number of public subnets and Number of private subnets. To select IP address ranges for your subnets, expand Customize subnets CIDR blocks. Otherwise, let AWS choose for you.\n  (Optional) If resources in a private subnet need public internet access via IPv4, for NAT gateways, choose the number of AZs you want to create NAT gateways in. In a production environment, we recommend deploying a NAT gateway in each AZ with resources that need public internet access. Note that there are associated costs with NAT gateways. For more information, see Pricing.\n  (Optional) If resources in a private subnet need public internet access via IPv6, for Egress-only Internet Gateway, select Yes.\n  (Optional) If you need direct access to Amazon S3 from your VPC, select VPC endpoints, S3 Gateway. This creates a VPC endpoint for Amazon S3. For more information, see VPC Endpoint Services in the AWS PrivateLink User Guide.\n  (Optional) For DNS options, both domain resolution options are enabled by default. If the defaults don\u0026rsquo;t meet your needs, you can disable these options.\n  (Optional) To add a tag to your VPC, expand Additional tags, choose Add new tag, and enter a tag key and tag value.\n  In the Preview pane, you can see the relationship diagram of the VPC resources you\u0026rsquo;ve configured. Solid lines represent relationships between resources. Dotted lines represent network traffic to NAT gateways, Internet gateways, and gateway endpoints. After creating the VPC, you can view your VPC resources in this format anytime using the Resource Map tab. For more information, see Viewing Resource Maps of Your VPC Resources.\n  When you\u0026rsquo;ve completed configuring your VPC, choose Create VPC.\n  Changing Public IPv4 Address Attribute for Your Subnet By default, non-default subnets have the Public IPv4 address attribute set to false, and default subnets have this attribute set to true. An exception is a non-default subnet created using the Amazon EC2 instance launch wizard - the wizard sets this attribute to true. You can change this attribute using the Amazon VPC interface.\nTo change the Public IPv4 address behavior for your subnet:\n  Open the Amazon VPC console https://console.aws.amazon.com/vpc/.\n  In the navigation pane, choose Subnets.\n  Select your subnet and choose Actions, Edit subnet settings.  The Auto-assign public IPv4 address checkbox, if selected, will require a Public IPv4 address for all instances launched into the selected subnet. Select or deselect the checkbox as needed, then choose Save.  "
},
{
	"uri": "/",
	"title": "Get Started with Amazon RDS",
	"tags": [],
	"description": "",
	"content": "Amazon Relational Database Service (Amazon RDS) Amazon Relational Database Service (Amazon RDS) is a managed service that you can use to launch and manage relational databases on AWS.\nOnline Transaction Processing (OLTP) Amazon RDS is an Online Transaction Processing (OLTP) type of database.\nPrimary Use Case The primary use case is a transactional database (rather than an analytical database). It is best suited to structured, relational data store requirements.\nDrop-in Replacement It aims to be a drop-in replacement for existing on-premises instances of the same databases.\nFeatures  Automated backups and patching are applied in customer-defined maintenance windows. Push-button scaling, replication, and redundancy.  Supported Database Engines Amazon RDS supports the following database engines:\n Amazon Aurora MySQL MariaDB Oracle SQL Server PostgreSQL  Managed Service RDS is a managed service, and you do not have access to the underlying EC2 instance (no root access).\nThe exception to the above rule is Amazon RDS Custom, which allows access to the underlying operating system. This is new, available for limited DB engines, and does not appear on the exam yet.\nManaged Service Includes The Amazon RDS managed service includes the following:\n Security and patching of the DB instances. Automated backup for the DB instances. Software updates for the DB engine. Easy scaling for storage and compute. Multi-AZ option with synchronous replication. Automatic failover for Multi-AZ option. Read replicas option for read-heavy workloads.  DB Instance A DB instance is a database environment in the cloud with the compute and storage resources you specify.\nAccess via Endpoints Database instances are accessed via endpoints. Endpoints can be retrieved via the DB instance description in the AWS Management Console, DescribeDBInstances API, or describe-db-instances command.\nInstance Limits By default, customers are allowed to have up to a total of 40 Amazon RDS DB instances (only 10 of these can be Oracle or MS SQL unless you have your own licenses).\nMaintenance Windows Maintenance windows are configured to allow DB instances modifications to take place, such as scaling and software patching (some operations require the DB instance to be taken offline briefly). You can define the maintenance window, or AWS will schedule a 30-minute window.\nWindows Integrated Authentication Windows integrated authentication for SQL only works with domains created using the AWS directory service – need to establish a trust with an on-premises AD directory.\nEvents and Notifications Amazon RDS uses AWS SNS to send RDS events via SNS notifications. You can use API calls to the Amazon RDS service to list the RDS events in the last 14 days (DescribeEvents API). You can view events from the last 14 days using the CLI. Using the AWS Console, you can only view RDS events for the last 1 day.\nUse Cases, Alternatives, and Anti-Patterns The table below provides guidance on when best to use RDS and several other AWS database/data store services:\n   Data Store When to Use     Database on EC2 - Ultimate control over the database    - Preferred DB not available under RDS   Amazon RDS - Need traditional relational database for OLTP    - Your data is well-formed and structured    - Existing apps requiring RDBMS   Amazon DynamoDB - Name/value pair data or unpredictable data structure    - In-memory performance with persistence    - High I/O needs    - Scale dynamically   Amazon RedShift - Massive amounts of data    - Primarily OLAP workloads   Amazon Neptune - Relationships between objects a major portion of data value   Amazon Elasticache - Fast temporary storage for small amounts of data    - Highly volatile data   Amazon S3 - BLOBs    - Static Websites    Alternative to Amazon RDS:\nIf your use case isn\u0026rsquo;t supported on RDS, you can run databases on Amazon EC2.\nConsider the following points when considering a DB on EC2:\n You can run any database you like with full control and ultimate flexibility. You must manage everything like backups, redundancy, patching, and scaling. Good option if you require a database not yet supported by RDS, such as IBM DB2 or SAP HANA. Good option if it is not feasible to migrate to an AWS-managed database.  Anti-Patterns:\nAnti-patterns are certain patterns in architecture or development that are considered bad or sub-optimal practices – i.e. there may be a better service or method to produce the best result.\nThe following table describes requirements that are not a good fit for RDS:\n   Requirement More Suitable Service     Lots of large binary objects (BLOBs) S3   Automated Scalability DynamoDB   Name/Value Data Structure DynamoDB   Data is not well structured or unpredictable DynamoDB   Other database platforms like IBM DB2 or SAP HANA EC2   Complete control over the database EC2    Encryption:\nYou can encrypt your Amazon RDS instances and snapshots at rest by enabling the encryption option for your Amazon RDS DB instance.\nEncryption at rest is supported for all DB types and uses AWS KMS.\nWhen using encryption at rest, the following elements are also encrypted:\n All DB snapshots. Backups. DB instance storage. Read Replicas.  You cannot encrypt an existing DB; you need to create a snapshot, copy it, encrypt the copy, then build an encrypted DB from the snapshot.\nData that is encrypted at rest includes the underlying storage for a DB instance, its automated backups, Read Replicas, and snapshots.\nA Read Replica of an Amazon RDS encrypted instance is also encrypted using the same key as the master instance when both are in the same region.\nIf the master and Read Replica are in different regions, you encrypt using the encryption key for that region.\nYou can\u0026rsquo;t have an encrypted Read Replica of an unencrypted DB instance or an unencrypted Read Replica of an encrypted DB instance.\nEncryption/decryption is handled transparently.\nRDS supports SSL encryption between applications and RDS DB instances.\nRDS generates a certificate for the instance.\nDB Subnet Groups A DB subnet group is a collection of subnets (typically private) that you create in a VPC and that you then designate for your DB instances.\nEach DB subnet group should have subnets in at least two Availability Zones in a given region.\nIt is recommended to configure a subnet group with subnets in each AZ (even for standalone instances).\nDuring the creation of an RDS instance, you can select the DB subnet group and the AZ within the group to place the RDS DB instance in.\nYou cannot pick the IP within the subnet that is allocated.\nBilling and Provisioning AWS Charge for:\n DB instance hours (partial hours are charged as full hours). Storage GB/month. I/O requests/month – for magnetic storage. Provisioned IOPS/month – for RDS provisioned IOPS SSD. Egress data transfer. Backup storage (DB backups and manual snapshots). Backup storage for the automated RDS backup is free of charge up to the provisioned EBS volume size.  However, AWS replicates data across multiple AZs, so you are charged for the extra storage space on S3.\nFor multi-AZ, you are charged for:\n Multi-AZ DB hours. Provisioned storage. Double write I/Os.  For multi-AZ, you are not charged for DB data transfer during replication from primary to standby.\nOracle and Microsoft SQL licenses are included, or you can bring your own (BYO).\nOn-demand and reserved instance pricing available.\nReserved instances are defined based on the following attributes which must not be changed:\n DB engine. DB instance class. Deployment type (standalone, multi-AZ). License model. Region.  Reserved instances:\n Can be moved between AZs in the same region. Are available for multi-AZ deployments. Can be applied to Read Replicas if DB instance class and region are the same.  Scaling is achieved through changing the instance class for compute and modifying storage capacity for additional storage allocation.\nScalability You can only scale RDS up (compute and storage).\nYou cannot decrease the allocated storage for an RDS instance.\nYou can scale storage and change the storage type for all DB engines except MS SQL.\nFor MS SQL, the workaround is to create a new instance from a snapshot with the new configuration.\nScaling storage can happen while the RDS instance is running without outage; however, there may be performance degradation.\nScaling compute will cause downtime.\nYou can choose to have changes take effect immediately, however, the default is within the maintenance window.\nScaling requests are applied during the specified maintenance window unless “apply immediately” is used.\nAll RDS DB types support a maximum DB size of 64 TiB except for Microsoft SQL Server (16 TiB).\nPerformance Amazon RDS uses EBS volumes (never uses instance store) for DB and log storage.\nThere are three storage types available: General Purpose (SSD), Provisioned IOPS (SSD), and Magnetic.\nGeneral Purpose (SSD):\n Use for Database workloads with moderate I/O requirement. Cost-effective. Also called gp2. 3 IOPS/GB. Burst up to 3000 IOPS.  Provisioned IOPS (SSD):\n Use for I/O intensive workloads. Low latency and consistent I/O. User-specified IOPS (see table below).  For provisioned IOPS storage, the table below shows the range of Provisioned IOPS and storage size range for each database engine.\n   Database Engine Range of Provisioned IOPS Range of Storage     MariaDB 1,000-80,000 IOPS 100 GiB-64TiB   SQL Server 1,000-64,000 IOPS 20 GiB-16TiB   MySQL 1,000-80,000 IOPS 100 GiB-64TiB   Oracle 1,000-256,000 IOPS 100 GiB-64TiB   PostgreSQL 1,000-80,000 IOPS 100 GiB-64TiB    Magnetic:\n Not recommended anymore, available for backward compatibility. Doesn’t allow you to scale storage when using the SQL Server database engine. Doesn’t support elastic volumes. Limited to a maximum size of 4 TiB. Limited to a maximum of 1,000 IOPS.  Multi-AZ and Read Replicas Multi-AZ and Read Replicas are used for high availability, fault tolerance, and performance scaling.\nThe table below compares multi-AZ deployments to Read Replicas:\n   Multi-AZ Deployments Read Replicas     Synchronous Replication – highly durable Asynchronous replication – highly scalable   Only database engine on primary instance is active All read replicas are accessible and can be used for read scaling   Automated backups are taken from standby No backups configured by default   Always span two availability zones within a single region Can be within an Availability Zone, Cross-AZ, or Cross-Region   Database engine version upgrades happen on primary Database engine version upgrade is independent from the source instance   Automatic failover to standby when a problem is detected Can be manually promoted to a standalone database instance    Multi-AZ Multi-AZ RDS creates a replica in another AZ and synchronously replicates to it (DR only).\nThere is an option to choose multi-AZ during the launch wizard.\nAWS recommends the use of provisioned IOPS storage for multi-AZ RDS DB instances.\nEach AZ runs on its own physically distinct, independent infrastructure, and is engineered to be highly reliable.\nYou cannot choose which AZ in the region will be chosen to create the standby DB instance.\nYou can view which AZ the standby DB instance is created in.\nA failover may be triggered in the following circumstances:\n Loss of primary AZ or primary DB instance failure. Loss of network connectivity on primary. Compute (EC2) unit failure on primary. Storage (EBS) unit failure on primary. The primary DB instance is changed. Patching of the OS on the primary DB instance. Manual failover (reboot with failover selected on primary).  During failover, RDS automatically updates configuration (including DNS endpoint) to use the second node.\nDepending on the instance class, it can take 1 to a few minutes to failover to a standby DB instance.\nIt is recommended to implement DB connection retries in your application.\nRecommended to use the endpoint rather than the IP address to point applications to the RDS DB.\nThe method to initiate a manual RDS DB instance failover is to reboot selecting the option to failover.\nA DB instance reboot is required for changes to take effect when you change the DB parameter group or when you change a static DB parameter.\nThe DB parameter group is a configuration container for the DB engine configuration.\nYou will be alerted by a DB instance event when a failover occurs.\nThe secondary DB in a multi-AZ configuration cannot be used as an independent read node (read or write).\nThere is no charge for data transfer between primary and secondary RDS instances.\nSystem upgrades like OS patching, DB Instance scaling, and system upgrades are applied first on the standby before failing over and modifying the other DB Instance.\nIn multi-AZ configurations, snapshots and automated backups are performed on the standby to avoid I/O suspension on the primary instance.\nRead Replica Support for Multi-AZ: Amazon RDS Read Replicas for MySQL, MariaDB, PostgreSQL, and Oracle support Multi-AZ deployments.\nCombining Read Replicas with Multi-AZ enables you to build a resilient disaster recovery strategy and simplify your database engine upgrade process.\nA Read Replica in a different region than the source database can be used as a standby database and promoted to become the new production database in case of a regional disruption.\nThis allows you to scale reads whilst also having multi-AZ for DR.\nThe process for implementing maintenance activities is as follows:\n Perform operations on standby. Promote standby to primary. Perform operations on new standby (demoted primary).  You can manually upgrade a DB instance to a supported DB engine version from the AWS Console.\nBy default, upgrades will take effect during the next maintenance window.\nYou can optionally force an immediate upgrade.\nIn multi-AZ deployments, version upgrades will be conducted on both the primary and standby at the same time, causing an outage of both DB instances.\nEnsure security groups and NACLs will allow your application servers to communicate with both the primary and standby instances.\nRead Replicas   Read replicas are used for read-heavy DBs, and replication is asynchronous.\n  Read replicas are for workload sharing and offloading.\n  Read replicas provide read-only DR.\n  Read replicas are created from a snapshot of the master instance.\n  Must have automated backups enabled on the primary (retention period \u0026gt; 0).\n  Only supported for transactional database storage engines (InnoDB not InnoDB).\n  Read replicas are available for MySQL, PostgreSQL, MariaDB, Oracle, Aurora, and SQL Server.\n  For the MySQL, MariaDB, PostgreSQL, and Oracle database engines, Amazon RDS creates a second DB instance using a snapshot of the source DB instance. It then uses the engines’ native asynchronous replication to update the read replica whenever there is a change to the source DB instance.\n  Amazon Aurora employs an SSD-backed virtualized storage layer purpose-built for database workloads.\n  You can take snapshots of PostgreSQL read replicas but cannot enable automated backups.\n  You can enable automatic backups on MySQL and MariaDB read replicas.\n  You can enable writes to the MySQL and MariaDB Read Replicas.\n  You can have 5 read replicas of a production DB.\n  You cannot have more than four instances involved in a replication chain.\n  You can have read replicas of read replicas for MySQL and MariaDB but not for PostgreSQL.\n  Read replicas can be configured from the AWS Console or the API.\n  You can specify the AZ the read replica is deployed in.\n  The read replica\u0026rsquo;s storage type and instance class can be different from the source but the compute should be at least the performance of the source.\n  You cannot change the DB engine.\n  In a multi-AZ failover, the read replicas are switched to the new primary.\n  Read replicas must be explicitly deleted.\n  If a source DB instance is deleted without deleting the replicas, each replica becomes a standalone single-AZ DB instance.\n  You can promote a read replica to primary.\n  Promotion of read replicas takes several minutes.\n  Promoted read replicas retain:\n Backup retention window. Backup window. DB parameter group.    Existing read replicas continue to function as normal.\n  Each read replica has its own DNS endpoint.\n  Read replicas can have multi-AZ enabled, and you can create read replicas of multi-AZ source DBs.\n  Read replicas can be in another region (uses asynchronous replication).\n  This configuration can be used for centralizing data from across different regions for analytics.\n  DB Snapshots DB Snapshots are user-initiated and enable you to back up your DB instance in a known state as frequently as you wish, and then restore to that specific state.\n Cannot be used for point-in-time recovery. Snapshots are stored on S3. Snapshots remain on S3 until manually deleted. Backups are taken within a defined window. I/O is briefly suspended while backups initialize and may increase latency (applicable to single-AZ RDS). DB snapshots that are performed manually will be stored even after the RDS instance is deleted. Restored DBs will always be a new RDS instance with a new DNS endpoint. Can restore up to the last 5 minutes. Only default DB parameters and security groups are restored – you must manually associate all other DB parameters and SGs. It is recommended to take a final snapshot before deleting an RDS instance. Snapshots can be shared with other AWS accounts.  High Availability Approaches for Databases If possible, choose DynamoDB over RDS because of inherent fault tolerance.\nIf DynamoDB can’t be used, choose Aurora because of redundancy and automatic recovery features.\nIf Aurora can’t be used, choose Multi-AZ RDS.\nFrequent RDS snapshots can protect against data corruption or failure, and they won’t impact the performance of Multi-AZ deployment.\nRegional replication is also an option but will not be strongly consistent.\nIf the database runs on EC2, you must design the HA yourself.\nMigration AWS Database Migration Service helps you migrate databases to AWS quickly and securely.\nUse along with the Schema Conversion Tool (SCT) to migrate databases to AWS RDS or EC2-based databases.\nThe source database remains fully operational during the migration, minimizing downtime to applications that rely on the database.\nThe AWS Database Migration Service can migrate your data to and from most widely used commercial and open-source databases.\nSchema Conversion Tool can copy database schemas for homogenous migrations (same database) and convert schemas for heterogeneous migrations (different database).\nDMS is used for smaller, simpler conversions and supports MongoDB and DynamoDB.\nSCT is used for larger, more complex datasets like data warehouses.\nDMS has replication functions for on-premises to AWS or to Snowball or S3.\nMonitoring, Logging, and Reporting You can use the following automated monitoring tools to watch Amazon RDS and report when something is wrong:\n Amazon RDS Events – Subscribe to Amazon RDS events to be notified when changes occur with a DB instance, DB snapshot, DB parameter group, or DB security group. Database log files – View, download, or watch database log files using the Amazon RDS console or Amazon RDS API operations. You can also query some database log files that are loaded into database tables. Amazon RDS Enhanced Monitoring — Look at metrics in real time for the operating system. Amazon RDS Performance Insights — Assess the load on your database and determine when and where to act. Amazon RDS Recommendations — Look at automated recommendations for database resources, such as DB instances, read replicas, and DB parameter groups.  In addition, Amazon RDS integrates with Amazon CloudWatch, Amazon EventBridge, and AWS CloudTrail for additional monitoring capabilities:\n Amazon CloudWatch Metrics – Amazon RDS automatically sends metrics to CloudWatch every minute for each active database. You don’t get additional charges for Amazon RDS metrics in CloudWatch. Amazon CloudWatch Alarms – You can watch a single Amazon RDS metric over a specific time period. You can then perform one or more actions based on the value of the metric relative to a threshold that you set. Amazon CloudWatch Logs – Most DB engines enable you to monitor, store, and access your database log files in CloudWatch Logs. Amazon CloudWatch Events and Amazon EventBridge – You can automate AWS services and respond to system events such as application availability issues or resource changes. Events from AWS services are delivered to CloudWatch Events and EventBridge nearly in real time. You can write simple rules to indicate which events interest you and what automated actions to take when an event matches a rule. AWS CloudTrail – You can view a record of actions taken by a user, role, or an AWS service in Amazon RDS. CloudTrail captures all API calls for Amazon RDS as events. These captures include calls from the Amazon RDS console and from code calls to the Amazon RDS API operations. If you create a trail, you can enable continuous delivery of CloudTrail events to an Amazon S3 bucket, including events for Amazon RDS. If you don’t configure a trail, you can still view the most recent events in the CloudTrail console in Event history.  "
},
{
	"uri": "/1-introduce/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Amazon Relational Database Service (Amazon RDS) Amazon Relational Database Service (Amazon RDS) is a managed service that you can use to launch and manage relational databases on AWS.\nOnline Transaction Processing (OLTP) Amazon RDS is an Online Transaction Processing (OLTP) type of database.\nPrimary Use Case The primary use case is a transactional database (rather than an analytical database). It is best suited to structured, relational data store requirements.\nDrop-in Replacement It aims to be a drop-in replacement for existing on-premises instances of the same databases.\nFeatures  Automated backups and patching are applied in customer-defined maintenance windows. Push-button scaling, replication, and redundancy.  Supported Database Engines Amazon RDS supports the following database engines:\n Amazon Aurora MySQL MariaDB Oracle SQL Server PostgreSQL  Managed Service RDS is a managed service, and you do not have access to the underlying EC2 instance (no root access).\nThe exception to the above rule is Amazon RDS Custom, which allows access to the underlying operating system. This is new, available for limited DB engines, and does not appear on the exam yet.\nManaged Service Includes The Amazon RDS managed service includes the following:\n Security and patching of the DB instances. Automated backup for the DB instances. Software updates for the DB engine. Easy scaling for storage and compute. Multi-AZ option with synchronous replication. Automatic failover for Multi-AZ option. Read replicas option for read-heavy workloads.  DB Instance A DB instance is a database environment in the cloud with the compute and storage resources you specify.\nAccess via Endpoints Database instances are accessed via endpoints. Endpoints can be retrieved via the DB instance description in the AWS Management Console, DescribeDBInstances API, or describe-db-instances command.\nInstance Limits By default, customers are allowed to have up to a total of 40 Amazon RDS DB instances (only 10 of these can be Oracle or MS SQL unless you have your own licenses).\nMaintenance Windows Maintenance windows are configured to allow DB instances modifications to take place, such as scaling and software patching (some operations require the DB instance to be taken offline briefly). You can define the maintenance window, or AWS will schedule a 30-minute window.\nWindows Integrated Authentication Windows integrated authentication for SQL only works with domains created using the AWS directory service – need to establish a trust with an on-premises AD directory.\nEvents and Notifications Amazon RDS uses AWS SNS to send RDS events via SNS notifications. You can use API calls to the Amazon RDS service to list the RDS events in the last 14 days (DescribeEvents API). You can view events from the last 14 days using the CLI. Using the AWS Console, you can only view RDS events for the last 1 day.\nUse Cases, Alternatives, and Anti-Patterns The table below provides guidance on when best to use RDS and several other AWS database/data store services:\n   Data Store When to Use     Database on EC2 - Ultimate control over the database    - Preferred DB not available under RDS   Amazon RDS - Need traditional relational database for OLTP    - Your data is well-formed and structured    - Existing apps requiring RDBMS   Amazon DynamoDB - Name/value pair data or unpredictable data structure    - In-memory performance with persistence    - High I/O needs    - Scale dynamically   Amazon RedShift - Massive amounts of data    - Primarily OLAP workloads   Amazon Neptune - Relationships between objects a major portion of data value   Amazon Elasticache - Fast temporary storage for small amounts of data    - Highly volatile data   Amazon S3 - BLOBs    - Static Websites    Alternative to Amazon RDS:\nIf your use case isn\u0026rsquo;t supported on RDS, you can run databases on Amazon EC2.\nConsider the following points when considering a DB on EC2:\n You can run any database you like with full control and ultimate flexibility. You must manage everything like backups, redundancy, patching, and scaling. Good option if you require a database not yet supported by RDS, such as IBM DB2 or SAP HANA. Good option if it is not feasible to migrate to an AWS-managed database.  Anti-Patterns:\nAnti-patterns are certain patterns in architecture or development that are considered bad or sub-optimal practices – i.e. there may be a better service or method to produce the best result.\nThe following table describes requirements that are not a good fit for RDS:\n   Requirement More Suitable Service     Lots of large binary objects (BLOBs) S3   Automated Scalability DynamoDB   Name/Value Data Structure DynamoDB   Data is not well structured or unpredictable DynamoDB   Other database platforms like IBM DB2 or SAP HANA EC2   Complete control over the database EC2    Encryption:\nYou can encrypt your Amazon RDS instances and snapshots at rest by enabling the encryption option for your Amazon RDS DB instance.\nEncryption at rest is supported for all DB types and uses AWS KMS.\nWhen using encryption at rest, the following elements are also encrypted:\n All DB snapshots. Backups. DB instance storage. Read Replicas.  You cannot encrypt an existing DB; you need to create a snapshot, copy it, encrypt the copy, then build an encrypted DB from the snapshot.\nData that is encrypted at rest includes the underlying storage for a DB instance, its automated backups, Read Replicas, and snapshots.\nA Read Replica of an Amazon RDS encrypted instance is also encrypted using the same key as the master instance when both are in the same region.\nIf the master and Read Replica are in different regions, you encrypt using the encryption key for that region.\nYou can\u0026rsquo;t have an encrypted Read Replica of an unencrypted DB instance or an unencrypted Read Replica of an encrypted DB instance.\nEncryption/decryption is handled transparently.\nRDS supports SSL encryption between applications and RDS DB instances.\nRDS generates a certificate for the instance.\nDB Subnet Groups A DB subnet group is a collection of subnets (typically private) that you create in a VPC and that you then designate for your DB instances.\nEach DB subnet group should have subnets in at least two Availability Zones in a given region.\nIt is recommended to configure a subnet group with subnets in each AZ (even for standalone instances).\nDuring the creation of an RDS instance, you can select the DB subnet group and the AZ within the group to place the RDS DB instance in.\nYou cannot pick the IP within the subnet that is allocated.\nBilling and Provisioning AWS Charge for:\n DB instance hours (partial hours are charged as full hours). Storage GB/month. I/O requests/month – for magnetic storage. Provisioned IOPS/month – for RDS provisioned IOPS SSD. Egress data transfer. Backup storage (DB backups and manual snapshots). Backup storage for the automated RDS backup is free of charge up to the provisioned EBS volume size.  However, AWS replicates data across multiple AZs, so you are charged for the extra storage space on S3.\nFor multi-AZ, you are charged for:\n Multi-AZ DB hours. Provisioned storage. Double write I/Os.  For multi-AZ, you are not charged for DB data transfer during replication from primary to standby.\nOracle and Microsoft SQL licenses are included, or you can bring your own (BYO).\nOn-demand and reserved instance pricing available.\nReserved instances are defined based on the following attributes which must not be changed:\n DB engine. DB instance class. Deployment type (standalone, multi-AZ). License model. Region.  Reserved instances:\n Can be moved between AZs in the same region. Are available for multi-AZ deployments. Can be applied to Read Replicas if DB instance class and region are the same.  Scaling is achieved through changing the instance class for compute and modifying storage capacity for additional storage allocation.\nScalability You can only scale RDS up (compute and storage).\nYou cannot decrease the allocated storage for an RDS instance.\nYou can scale storage and change the storage type for all DB engines except MS SQL.\nFor MS SQL, the workaround is to create a new instance from a snapshot with the new configuration.\nScaling storage can happen while the RDS instance is running without outage; however, there may be performance degradation.\nScaling compute will cause downtime.\nYou can choose to have changes take effect immediately, however, the default is within the maintenance window.\nScaling requests are applied during the specified maintenance window unless “apply immediately” is used.\nAll RDS DB types support a maximum DB size of 64 TiB except for Microsoft SQL Server (16 TiB).\nPerformance Amazon RDS uses EBS volumes (never uses instance store) for DB and log storage.\nThere are three storage types available: General Purpose (SSD), Provisioned IOPS (SSD), and Magnetic.\nGeneral Purpose (SSD):\n Use for Database workloads with moderate I/O requirement. Cost-effective. Also called gp2. 3 IOPS/GB. Burst up to 3000 IOPS.  Provisioned IOPS (SSD):\n Use for I/O intensive workloads. Low latency and consistent I/O. User-specified IOPS (see table below).  For provisioned IOPS storage, the table below shows the range of Provisioned IOPS and storage size range for each database engine.\n   Database Engine Range of Provisioned IOPS Range of Storage     MariaDB 1,000-80,000 IOPS 100 GiB-64TiB   SQL Server 1,000-64,000 IOPS 20 GiB-16TiB   MySQL 1,000-80,000 IOPS 100 GiB-64TiB   Oracle 1,000-256,000 IOPS 100 GiB-64TiB   PostgreSQL 1,000-80,000 IOPS 100 GiB-64TiB    Magnetic:\n Not recommended anymore, available for backward compatibility. Doesn’t allow you to scale storage when using the SQL Server database engine. Doesn’t support elastic volumes. Limited to a maximum size of 4 TiB. Limited to a maximum of 1,000 IOPS.  Multi-AZ and Read Replicas Multi-AZ and Read Replicas are used for high availability, fault tolerance, and performance scaling.\nThe table below compares multi-AZ deployments to Read Replicas:\n   Multi-AZ Deployments Read Replicas     Synchronous Replication – highly durable Asynchronous replication – highly scalable   Only database engine on primary instance is active All read replicas are accessible and can be used for read scaling   Automated backups are taken from standby No backups configured by default   Always span two availability zones within a single region Can be within an Availability Zone, Cross-AZ, or Cross-Region   Database engine version upgrades happen on primary Database engine version upgrade is independent from the source instance   Automatic failover to standby when a problem is detected Can be manually promoted to a standalone database instance    Multi-AZ Multi-AZ RDS creates a replica in another AZ and synchronously replicates to it (DR only).\nThere is an option to choose multi-AZ during the launch wizard.\nAWS recommends the use of provisioned IOPS storage for multi-AZ RDS DB instances.\nEach AZ runs on its own physically distinct, independent infrastructure, and is engineered to be highly reliable.\nYou cannot choose which AZ in the region will be chosen to create the standby DB instance.\nYou can view which AZ the standby DB instance is created in.\nA failover may be triggered in the following circumstances:\n Loss of primary AZ or primary DB instance failure. Loss of network connectivity on primary. Compute (EC2) unit failure on primary. Storage (EBS) unit failure on primary. The primary DB instance is changed. Patching of the OS on the primary DB instance. Manual failover (reboot with failover selected on primary).  During failover, RDS automatically updates configuration (including DNS endpoint) to use the second node.\nDepending on the instance class, it can take 1 to a few minutes to failover to a standby DB instance.\nIt is recommended to implement DB connection retries in your application.\nRecommended to use the endpoint rather than the IP address to point applications to the RDS DB.\nThe method to initiate a manual RDS DB instance failover is to reboot selecting the option to failover.\nA DB instance reboot is required for changes to take effect when you change the DB parameter group or when you change a static DB parameter.\nThe DB parameter group is a configuration container for the DB engine configuration.\nYou will be alerted by a DB instance event when a failover occurs.\nThe secondary DB in a multi-AZ configuration cannot be used as an independent read node (read or write).\nThere is no charge for data transfer between primary and secondary RDS instances.\nSystem upgrades like OS patching, DB Instance scaling, and system upgrades are applied first on the standby before failing over and modifying the other DB Instance.\nIn multi-AZ configurations, snapshots and automated backups are performed on the standby to avoid I/O suspension on the primary instance.\nRead Replica Support for Multi-AZ: Amazon RDS Read Replicas for MySQL, MariaDB, PostgreSQL, and Oracle support Multi-AZ deployments.\nCombining Read Replicas with Multi-AZ enables you to build a resilient disaster recovery strategy and simplify your database engine upgrade process.\nA Read Replica in a different region than the source database can be used as a standby database and promoted to become the new production database in case of a regional disruption.\nThis allows you to scale reads whilst also having multi-AZ for DR.\nThe process for implementing maintenance activities is as follows:\n Perform operations on standby. Promote standby to primary. Perform operations on new standby (demoted primary).  You can manually upgrade a DB instance to a supported DB engine version from the AWS Console.\nBy default, upgrades will take effect during the next maintenance window.\nYou can optionally force an immediate upgrade.\nIn multi-AZ deployments, version upgrades will be conducted on both the primary and standby at the same time, causing an outage of both DB instances.\nEnsure security groups and NACLs will allow your application servers to communicate with both the primary and standby instances.\nRead Replicas   Read replicas are used for read-heavy DBs, and replication is asynchronous.\n  Read replicas are for workload sharing and offloading.\n  Read replicas provide read-only DR.\n  Read replicas are created from a snapshot of the master instance.\n  Must have automated backups enabled on the primary (retention period \u0026gt; 0).\n  Only supported for transactional database storage engines (InnoDB not InnoDB).\n  Read replicas are available for MySQL, PostgreSQL, MariaDB, Oracle, Aurora, and SQL Server.\n  For the MySQL, MariaDB, PostgreSQL, and Oracle database engines, Amazon RDS creates a second DB instance using a snapshot of the source DB instance. It then uses the engines’ native asynchronous replication to update the read replica whenever there is a change to the source DB instance.\n  Amazon Aurora employs an SSD-backed virtualized storage layer purpose-built for database workloads.\n  You can take snapshots of PostgreSQL read replicas but cannot enable automated backups.\n  You can enable automatic backups on MySQL and MariaDB read replicas.\n  You can enable writes to the MySQL and MariaDB Read Replicas.\n  You can have 5 read replicas of a production DB.\n  You cannot have more than four instances involved in a replication chain.\n  You can have read replicas of read replicas for MySQL and MariaDB but not for PostgreSQL.\n  Read replicas can be configured from the AWS Console or the API.\n  You can specify the AZ the read replica is deployed in.\n  The read replica\u0026rsquo;s storage type and instance class can be different from the source but the compute should be at least the performance of the source.\n  You cannot change the DB engine.\n  In a multi-AZ failover, the read replicas are switched to the new primary.\n  Read replicas must be explicitly deleted.\n  If a source DB instance is deleted without deleting the replicas, each replica becomes a standalone single-AZ DB instance.\n  You can promote a read replica to primary.\n  Promotion of read replicas takes several minutes.\n  Promoted read replicas retain:\n Backup retention window. Backup window. DB parameter group.    Existing read replicas continue to function as normal.\n  Each read replica has its own DNS endpoint.\n  Read replicas can have multi-AZ enabled, and you can create read replicas of multi-AZ source DBs.\n  Read replicas can be in another region (uses asynchronous replication).\n  This configuration can be used for centralizing data from across different regions for analytics.\n  DB Snapshots DB Snapshots are user-initiated and enable you to back up your DB instance in a known state as frequently as you wish, and then restore to that specific state.\n Cannot be used for point-in-time recovery. Snapshots are stored on S3. Snapshots remain on S3 until manually deleted. Backups are taken within a defined window. I/O is briefly suspended while backups initialize and may increase latency (applicable to single-AZ RDS). DB snapshots that are performed manually will be stored even after the RDS instance is deleted. Restored DBs will always be a new RDS instance with a new DNS endpoint. Can restore up to the last 5 minutes. Only default DB parameters and security groups are restored – you must manually associate all other DB parameters and SGs. It is recommended to take a final snapshot before deleting an RDS instance. Snapshots can be shared with other AWS accounts.  High Availability Approaches for Databases If possible, choose DynamoDB over RDS because of inherent fault tolerance.\nIf DynamoDB can’t be used, choose Aurora because of redundancy and automatic recovery features.\nIf Aurora can’t be used, choose Multi-AZ RDS.\nFrequent RDS snapshots can protect against data corruption or failure, and they won’t impact the performance of Multi-AZ deployment.\nRegional replication is also an option but will not be strongly consistent.\nIf the database runs on EC2, you must design the HA yourself.\nMigration AWS Database Migration Service helps you migrate databases to AWS quickly and securely.\nUse along with the Schema Conversion Tool (SCT) to migrate databases to AWS RDS or EC2-based databases.\nThe source database remains fully operational during the migration, minimizing downtime to applications that rely on the database.\nThe AWS Database Migration Service can migrate your data to and from most widely used commercial and open-source databases.\nSchema Conversion Tool can copy database schemas for homogenous migrations (same database) and convert schemas for heterogeneous migrations (different database).\nDMS is used for smaller, simpler conversions and supports MongoDB and DynamoDB.\nSCT is used for larger, more complex datasets like data warehouses.\nDMS has replication functions for on-premises to AWS or to Snowball or S3.\nMonitoring, Logging, and Reporting You can use the following automated monitoring tools to watch Amazon RDS and report when something is wrong:\n Amazon RDS Events – Subscribe to Amazon RDS events to be notified when changes occur with a DB instance, DB snapshot, DB parameter group, or DB security group. Database log files – View, download, or watch database log files using the Amazon RDS console or Amazon RDS API operations. You can also query some database log files that are loaded into database tables. Amazon RDS Enhanced Monitoring — Look at metrics in real time for the operating system. Amazon RDS Performance Insights — Assess the load on your database and determine when and where to act. Amazon RDS Recommendations — Look at automated recommendations for database resources, such as DB instances, read replicas, and DB parameter groups.  In addition, Amazon RDS integrates with Amazon CloudWatch, Amazon EventBridge, and AWS CloudTrail for additional monitoring capabilities:\n Amazon CloudWatch Metrics – Amazon RDS automatically sends metrics to CloudWatch every minute for each active database. You don’t get additional charges for Amazon RDS metrics in CloudWatch. Amazon CloudWatch Alarms – You can watch a single Amazon RDS metric over a specific time period. You can then perform one or more actions based on the value of the metric relative to a threshold that you set. Amazon CloudWatch Logs – Most DB engines enable you to monitor, store, and access your database log files in CloudWatch Logs. Amazon CloudWatch Events and Amazon EventBridge – You can automate AWS services and respond to system events such as application availability issues or resource changes. Events from AWS services are delivered to CloudWatch Events and EventBridge nearly in real time. You can write simple rules to indicate which events interest you and what automated actions to take when an event matches a rule. AWS CloudTrail – You can view a record of actions taken by a user, role, or an AWS service in Amazon RDS. CloudTrail captures all API calls for Amazon RDS as events. These captures include calls from the Amazon RDS console and from code calls to the Amazon RDS API operations. If you create a trail, you can enable continuous delivery of CloudTrail events to an Amazon S3 bucket, including events for Amazon RDS. If you don’t configure a trail, you can still view the most recent events in the CloudTrail console in Event history.  "
},
{
	"uri": "/2-prerequiste/2-create-ec2-sg/",
	"title": "Create EC2 Security Group",
	"tags": [],
	"description": "",
	"content": "Creating a Security Group on AWS with Ports 80, 443, 5000, and 22   Log in to the AWS Management Console.\n  In the main menu, select Services, and then choose EC2 under Compute.\n  On the left-hand side, you will see Network \u0026amp; Security. Select Security Groups.\n  Click the Create Security Group button to begin the creation process.\n  Fill in basic information such as the name and description for your Security Group.  In the Inbound rules section, add the following rules to allow access to specific ports:  HTTP (80): Select HTTP from the list or enter port 80. HTTPS (443): Select HTTPS from the list or enter port 443. Custom TCP Rule (5000): Select Custom TCP Rule and enter port 5000. SSH (22): Select SSH from the list or enter port 22.    After adding the rules, click the Create security group button.  Your Security Group is now created, and you can associate it with your EC2 resources to manage access to these ports.  "
},
{
	"uri": "/2-prerequiste/",
	"title": "Preparation steps",
	"tags": [],
	"description": "",
	"content": "Preparation Steps  Create VPC Create Subnet Create Security Group for Amazon EC2 Create Security Group for DB instance Create DB Subnet Group  "
},
{
	"uri": "/3-create-ec2/",
	"title": "Create EC2 instance",
	"tags": [],
	"description": "",
	"content": "Creating an AWS Instance To create a Linux instance using AWS Management Console, follow the instructions below. This guide is designed to help you quickly create your first instance, so it doesn\u0026rsquo;t include all possible options. For information on advanced options, refer to the Launch Instance documentation.\n  Access AWS Console\n Open a web browser and go to the Amazon EC2 console at https://console.aws.amazon.com/ec2/.    Choose Launch instance\n On the EC2 console dashboard, in the Launch instance box, select Launch instance, then choose Launch instance from the options that appear.    Name your instance\n Under the Name and tags section, for Name, enter a descriptive name for your instance.    Select an image (Amazon Machine Image - AMI)\n Under Application and OS Images (Amazon Machine Image), follow these steps:  Choose Quick Start, then select Amazon Linux. This is the operating system (OS) for your instance. From the Amazon Machine Image (AMI), choose an HVM version of Amazon Linux 2023. Note that these AMIs are marked as Free tier eligible. An Amazon Machine Image (AMI) is a basic configuration used as a template for your instance.      Choose instance type\n Under the Instance type section, from the Instance type list, you can select the hardware configuration for your instance. Choose the t2.micro instance type, which is pre-selected by default. The t2.micro instance type qualifies for free usage in the AWS Free Tier. In regions where t2.micro isn\u0026rsquo;t available, you can use t3.micro in the AWS Free Tier. For more information, refer to AWS Free Tier.    Choose Key Pair\n  Under the Key pair (login) section, for Key pair name, select the key pair you created during setup.\n  Warning: Do not select Proceed without a key pair (Not recommended). If you launch an instance without a key pair, you won\u0026rsquo;t be able to connect to it.\n    Configure Security Group\n  Under Network settings, select Edit. For Security group name, you\u0026rsquo;ll see that the guide has created and selected a security group for you. You can use this security group or choose one you created during setup using the following steps:\n Select Select existing security group. From Common security groups, choose your security group from the list of available security groups.      Review and launch the instance\n Keep the default choices for other settings of your instance. Review a summary of your instance configuration in the Summary panel, and when you\u0026rsquo;re ready, choose Launch instance.    Confirmation and verification\n A confirmation page will indicate that your instance is starting. Select View all instances to close the confirmation page and return to the console interface. On the Instances screen, you can see the status of the startup process. There is a brief time for the instance to start. When you launch an instance, its initial state is pending. After the instance starts, its status will change to running, and it will receive a public DNS name. If the Public IPv4 DNS column is hidden, select the gear icon (Settings) in the upper right corner, enable Public IPv4 DNS, and select Confirm. It may take a few minutes for the instance to be ready for you to connect to. Check if your instance has passed the status check; you can see this information in the Status check column.    Connecting to EC2 Instance via SSH using Mobaxterm To connect to an Amazon Elastic Compute Cloud (EC2) instance via SSH using Mobaxterm, follow these steps:\n  Download and Install Mobaxterm:\n First, download Mobaxterm from the official website: Mobaxterm Website. After downloading, install Mobaxterm on your computer.    Open Mobaxterm:\n Launch Mobaxterm after installation.    Create a New SSH Connection:\n In Mobaxterm, you can create a new SSH connection by clicking the Session icon in the upper-left corner of the interface.    Configure the SSH Connection:\n In the configuration window, enter the following information:  Remote Host: Enter the IP address or domain name of the EC2 instance you want to connect to. Port: The default is 22 (SSH port). User: The username on the EC2 instance (usually ec2-user or ubuntu). Advanced SSH settings: Here, you can provide an SSH key (private key) if you\u0026rsquo;re using key-based authentication instead of a password.      Connect to the EC2 Instance:\n Click OK to save the configuration, and then click the connect icon to establish an SSH connection to your EC2 instance.    Enter Password (if applicable):\n If you\u0026rsquo;re using a password instead of an SSH key, Mobaxterm will prompt you to enter the user\u0026rsquo;s password on the EC2 instance.    Successful Connection:\n  If all the information is correct, you will successfully connect to the EC2 instance and can perform remote server tasks.\n  Remember that you need to have access permissions to the EC2 instance and have configured its Security Group to allow SSH connections from your IP address.\n    "
},
{
	"uri": "/2-prerequiste/3-create-db-sg/",
	"title": "Create RDS Security group",
	"tags": [],
	"description": "",
	"content": "Create a Security Group for a DB Instance in AWS You can use a Security Group to control access to a private DB instance in the AWS environment. Below are the steps to create a Security Group for a DB instance in the VPC interface:\n  In the VPC interface, select Security Groups.\n  Choose Create Security Group to create a new Security Group for the private DB instance.\n  Provide a name for the Security Group:\n Security Group Name: Enter a name for the Security Group. Description: Enter a description for the Security Group.     Select the VPC you have created to associate the Security Group with it.\n  Configure Inbound rules to determine which sources are allowed to access the DB instance. For example:\n Choose MYSQL/Aurora and port 3306. Custom Source: Enter the ID of the Security Group of the Amazon EC2 instance you want to connect to the DB instance.    Once you have finished configuring, select Create Security Group to complete the process of creating a Security Group for the DB instance.  Congratulations! You have successfully created a Security Group for a private DB instance in the AWS environment.\n Note: It is not recommended to share Security Groups between DB instances and Amazon EC2 instances to ensure separate security and management for each resource.\n "
},
{
	"uri": "/2-prerequiste/4-create-db-subnetgroup/",
	"title": "Create DB Subnet Group",
	"tags": [],
	"description": "",
	"content": "Creating a DB Subnet Group on AWS To create a DB Subnet Group on AWS, follow these steps:\n  Access the AWS Management Console.\n  Locate and select the Amazon RDS service.\n  In the navigation menu, choose Subnet groups.\n  Select Create DB Subnet Group.\n   In the Create DB Subnet Group interface:\n  Set a name for your subnet group in the Name field.\n  Enter a description for your subnet group in the Description field.\n  Choose the default Virtual Private Cloud (VPC) or the VPC you have created.\n     In the Add subnets section, select the Availability Zones (AZ) containing the subnets from the Availability Zones section, and then choose the subnets from the Subnets section.\n  Press the Create button to complete the DB Subnet Group creation process.\n  Note: If you have enabled Local Zone, you can select an Availability Zone group on the Create DB Subnet Group page. In this case, select the Availability Zone group, the corresponding Availability Zones, and Subnets.\nOnce completed, your new DB Subnet Group will appear in the list of DB Subnet Groups on the RDS console interface. You can select the DB Subnet Group to view details, including the list of subnets associated with this group, in the details section at the bottom of the window.\n"
},
{
	"uri": "/4-create-rds/",
	"title": "Create RDS database instance",
	"tags": [],
	"description": "",
	"content": "Install Git on Amazon EC2 2023 Below are instructions for installing Git on an Amazon EC2 virtual machine running Amazon Linux 2023 using basic steps.\n Update System Packages  First, update your system packages to make sure you\u0026rsquo;re using the latest version:\nsudo dnf update -y Find Git Packages. Use the following command to find Git packages in the repository:  sudo dnf search git Install Git. Once you find the Git package, you can install it with the following command:  sudo dnf install git -y Verify Git Settings. Finally, check the Git version was successfully installed:  git --version If you see the Git version appear, it means the installation is complete.\nInstall Node.js on Amazon EC2 Linux 2023   Below is a Bash script to install Node.js on Amazon EC2 Linux:  #!/bin/bash\r# Color for formatting\rGREEN=\u0026#39;\\033[0;32m\u0026#39;\rNC=\u0026#39;\\033[0m\u0026#39; # Colorless\r# Check if NVM is installed\rif ! command -v nvm \u0026amp;\u0026gt; /dev/null; then\r# Step 1: Install nvm\rcurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash\rsource ~/.nvm/nvm.sh\rfi\r# Verify nvm installation\rnvm --version\r# Install the LTS version of Node.js\rnvm install --lts\r# Use the installed LTS version\rnvm use --lts\r# Verify Node.js and npm installation\rnode -v\rnpm -v\r# Step 4: Create package.json file (if it doesn\u0026#39;t exist yet)\rif [ ! -f package.json ]; then\rnpm init -y\recho -e **${GREEN}Created file package.json.${NC}**\rfi\r#Step 5: Install necessary npm packages\recho -e **Installing required npm packages...**\rnpm install express dotenv express-handlebars body-parser mysql\r#Step 6: Install nodemon as a development dependency\recho -e **Installing nodemon as a development dependency...**\rnpm install --save-dev nodemon\rnpm install -g nodemon\r# Step 7: Add npm start script to package.json\rif ! grep -q \u0026#39;**start**:\u0026#39; package.json; then\rnpm set-script start **index.js** # Replace **your-app.js** with your entry point file\recho -e **${GREEN}Added npm start script to package.json.${NC}**\rfi\recho -e **${GREEN}Installation completed. You can now start building and running your Node.js application using \u0026#39;npm start\u0026#39;.${NC}** Creating a DB Instance on AWS To create a DB Instance on AWS, you can use the AWS Management Console with the option of Easy create either enabled or disabled. When Easy create is enabled, you only need to specify the DB engine type, DB Instance size, and DB Instance identifier. Easy create uses default settings for other configuration options. When Easy create is disabled, you need to specify more configuration options when creating a database, including options for availability, security, backups, and maintenance.\nNote: In the procedure below, the Standard create option is enabled, and Easy create is not. This procedure uses MySQL as an example.\nFor an example using Easy create to guide you in creating and connecting sample DB Instances for each engine, see Getting Started with Amazon RDS.\nTo create a DB Instance:\n  Sign in to the AWS Management Console and open the Amazon RDS console at https://console.aws.amazon.com/rds/.\n  In the upper right corner of the Amazon RDS console, select the AWS region where you want to create the DB Instance.\n  In the navigation pane, choose Databases.\n  Choose Create database, and then select Standard create.\n   For Engine type, choose MariaDB, Microsoft SQL Server, MySQL, Oracle, or PostgreSQL. In this example, we are using Microsoft SQL Server.\n  For Database management type, if you are using Oracle or SQL Server, select Amazon RDS or Amazon RDS Custom.\n  For Edition, if you are using Oracle or SQL Server, select the version of the DB engine you want to use.\n  For Version, select the engine version.\n  In the Templates section, choose a template that matches your use case. If you choose Production, the following options will be pre-selected in the next step:\n Multi-AZ failover option Provisioned IOPS SSD (io1) storage option Protection against deletion option  We recommend using these features for a production environment.\n  Note: Template choices may vary by version.\n To enter your master password, follow these steps:\n In the Settings section, open Credential Settings. If you want to specify a password, uncheck the Auto generate a password box if it\u0026rsquo;s already selected. (Optional) Change the Master username value. Enter the same password in both Master password and Confirm password. (Optional) Set up a connection to a compute resource for this DB Instance.     You can configure the connection between an Amazon EC2 instance and the new DB Instance during the DB Instance creation process. For more information, see Configuring Automatic Network Connectivity to an EC2 Instance.\n  In the Connectivity section under VPC security group (firewall), if you choose Create new, a VPC security group with a login rule allowing your local computer\u0026rsquo;s IP address to access the database will be created.\n   For the remaining sections, specify your DB Instance settings. For more information on each setting, see Settings for DB Instances.\n  Choose Create database.\n   If you choose to use an automatically generated password, the View credential details button will appear on the Databases page.\n  To view the master username and password for the DB Instance, select View credential details.\n  To connect to the DB Instance using the master username, use the displayed username and password.\n  Important: You cannot review the master user password. If you don\u0026rsquo;t record it, you may need to change it. If you need to change the master user password after the DB Instance is available, you can modify the DB Instance to do this. For more information on modifying a DB Instance, see Modifying an Amazon RDS DB Instance.\nUnder Databases, select the name of the new DB Instance.  On the RDS console, information about the new DB Instance will appear. The DB Instance will have a Creating status until it is created and ready for use. Once the status changes to Available, you can connect to the DB Instance. Depending on the DB Instance class and allocated storage, it may take a few minutes for the new DB Instance to be available.  Check RDS   In the details page of the RDS instance, you can find connection-related information such as Endpoint, Port, and Username. The Endpoint is the URL or IP address you use to connect to the RDS database.  Viewing Logs and Events on AWS RDS To monitor Logs and Events on Amazon RDS (Relational Database Service), you can follow these steps:\n  Sign in to the AWS Management Console.\n  Choose the Amazon RDS service from the AWS dashboard.\n  Select the RDS instance you want to view Logs and Events for.\n  In the instance details page, you will see the following tabs:\n DB instance details: Displays basic information about the instance. Configuration: Allows you to view and modify the instance\u0026rsquo;s configuration. Log \u0026amp; events: This is where you can view Logs and Events.    Click on the Log \u0026amp; events tab. Here, you can view various logs such as:\n Error log: Records errors that occur on the instance. General log: Records general activities on the instance. Slow query log: Records slow queries. Event log: Displays important events related to the instance.    You can customize settings for viewing Logs and Events here, such as the time range you want to view logs or setting up email notifications for important events.\n  Remember to regularly review logs and events to monitor the status of your Amazon RDS instance and detect any issues early.\nViewing Maintenance and Backups on AWS RDS In Amazon Web Services (AWS), Amazon Relational Database Service (RDS) provides an easy-to-manage relational database with automation for various tasks, including maintenance and backups. Here\u0026rsquo;s how you can view information about maintenance and backups in AWS RDS:\nViewing Maintenance Information To view information about maintenance for a DB instance in RDS, you can follow these steps:\n  Sign in to the AWS Management Console.\n  Choose the Amazon RDS service from the list of services.\n  In the RDS dashboard, select the DB instance you are interested in.\n  In the DB instance management page, navigate to the Maintenance \u0026amp; backups tab.\n  Here, you will see information about the maintenance schedule, including the times when the DB instance will be automatically backed up and maintenance tasks will be performed. You can also view the history of previous maintenance events.\n  Viewing Backup Information To view information about backups of a DB instance in AWS RDS, follow these steps:\n  Sign in to the AWS Management Console.\n  Choose the Amazon RDS service from the list of services.\n  In the RDS dashboard, select the DB instance you want to check.\n  In the DB instance management page, navigate to the Maintenance \u0026amp; backups tab.\n  Here, you can view information about automatic backups and manual backups. You can also configure and manage backup settings.\n  Make sure to follow relevant rules and policies when performing any tasks on AWS RDS to ensure the security and safety of your data.\n"
},
{
	"uri": "/5-deploy-app/",
	"title": "Application Deployment",
	"tags": [],
	"description": "",
	"content": "Deploy the application  To clone the repository from GitHub of AWS-First-Cloud-Journey, you can use the following command:  git clone https://github.com/AWS-First-Cloud-Journey/AWS-FCJ-Management #Instructions for installing Node.js on Amazon Linux 2023  Below is a Bash script to install Node.js on Amazon Linux. Please copy and execute the following steps:\n#!/bin/bash\r# Các màu cho định dạng\rGREEN=\u0026#39;\\033[0;32m\u0026#39;\rNC=\u0026#39;\\033[0m\u0026#39; # Không màu\r# Kiểm tra xem NVM đã được cài đặt chưa\rif ! command -v nvm \u0026amp;\u0026gt; /dev/null; then\r# Bước 1: Cài đặt nvm\rcurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash\rsource ~/.nvm/nvm.sh\rfi\r# Xác minh việc cài đặt nvm\rnvm --version\r# Cài đặt phiên bản LTS của Node.js\rnvm install --lts\r# Sử dụng phiên bản LTS đã cài đặt\rnvm use --lts\r# Xác minh cài đặt Node.js và npm\rnode -v\rnpm -v\r# Bước 4: Tạo tệp package.json (nếu nó chưa tồn tại)\rif [ ! -f package.json ]; then\rnpm init -y\recho -e \u0026#34;${GREEN}Đã tạo tệp package.json.${NC}\u0026#34;\rfi\r# Bước 5: Cài đặt các gói npm cần thiết\recho -e \u0026#34;Đang cài đặt các gói npm cần thiết...\u0026#34;\rnpm install express dotenv express-handlebars body-parser mysql\r# Bước 6: Cài đặt nodemon như một phần phát triển\recho -e \u0026#34;Đang cài đặt nodemon như một phần phát triển...\u0026#34;\rnpm install --save-dev nodemon\rnpm install -g nodemon\r# Bước 7: Thêm script npm start vào package.json\rif ! grep -q \u0026#39;\u0026#34;start\u0026#34;:\u0026#39; package.json; then\rnpm set-script start \u0026#34;index.js\u0026#34; # Thay thế \u0026#34;your-app.js\u0026#34; bằng tệp điểm nhập của bạn\recho -e \u0026#34;${GREEN}Đã thêm script npm start vào package.json.${NC}\u0026#34;\rfi\recho -e \u0026#34;${GREEN}Cài đặt hoàn tất. Bây giờ bạn có thể bắt đầu xây dựng và chạy ứng dụng Node.js của mình bằng \u0026#39;npm start\u0026#39;.${NC}\u0026#34; This is a Bash script used to install and configure MySQL server on a system. This script performs the following steps:    Set variables with MySQL RPM path and database information such as RDS address, database name, username and password.\n  Check if the MySQL community repository RPM already exists in the current directory. If it does not exist, it will download the RPM from the specified URL.\n  Install RPM of MySQL community repository and MySQL Server.\n  Start the MySQL server and configure it to automatically start with the system.\n  Check the installed MySQL version.\n  Secure the MySQL server with the mysql_secure_installation command.\n  Create or update an .env file with database information (address, database name, username, and password).\n  Connect to MySQL server with credentials and you can add specific SQL commands here.\n   Note: To execute this script, you need to have sudo permissions and make sure you have provided the correct database information (RDS Endpoint, database name, username and password) before run script.\n #!/bin/bash\r# Set variables for MySQL RPM and database information\rMYSQL_RPM_URL=\u0026#34;https://dev.mysql.com/get/mysql80-community-release-el9-1.noarch.rpm\u0026#34;\rDB_HOST=\u0026#34;RDS Endpoint\u0026#34;\rDB_NAME=\u0026#34;Database name\u0026#34;\rDB_USER=\u0026#34;Database username\u0026#34;\rDB_PASS=\u0026#34;Database password\u0026#34;\r# Check if MySQL Community repository RPM already exists\rif [ ! -f mysql80-community-release-el9-1.noarch.rpm ]; then\rsudo wget $MYSQL_RPM_URL\rfi\r# Install MySQL Community repository\rsudo dnf install -y mysql80-community-release-el9-1.noarch.rpm\r# Install MySQL server\rsudo dnf install -y mysql-community-server\r# Start MySQL server\rsudo systemctl start mysqld\r# Enable MySQL to start on boot\rsudo systemctl enable mysqld\r# Check MySQL version\rmysql -V\r# Secure the MySQL server\rsudo mysql_secure_installation\r# Create or update the .env file with database information\recho \u0026#34;DB_HOST=$DB_HOST\u0026#34; \u0026gt;\u0026gt; .env\recho \u0026#34;DB_NAME=$DB_NAME\u0026#34; \u0026gt;\u0026gt; .env\recho \u0026#34;DB_USER=$DB_USER\u0026#34; \u0026gt;\u0026gt; .env\recho \u0026#34;DB_PASS=$DB_PASS\u0026#34; \u0026gt;\u0026gt; .env\r# Connect to MySQL and create a new database (you might want to add specific SQL commands here)\rmysql -h $DB_HOST -P 3306 -u $DB_USER -p$DB_PASS Create Database and Table in AWS RDS  After successfully connecting to RDS (Relational Database Service) on AWS, we can create a new database and define a table in it using the following SQL script.\nCreate Database First, we will create a new database if it does not exist yet. Use the following command:\nCREATE DATABASE IF NOT EXISTS first_cloud_users; This command checks whether the database \u0026ldquo;first_cloud_users\u0026rdquo; exists or not. If it does not exist, it will create a new database named \u0026ldquo;first_cloud_users\u0026rdquo;.\nUsing Database Next, we use the \u0026ldquo;first_cloud_users\u0026rdquo; database using the command:\nUSE first_cloud_users; This command indicates that all SQL commands will then be executed in the \u0026ldquo;first_cloud_users\u0026rdquo; database.\nCreate Table \u0026ldquo;user\u0026rdquo; We have created the database and used it. Now, we will define a \u0026ldquo;user\u0026rdquo; table in this database using the following SQL script:\nCREATE TABLE `user`\r(\r`id` INT NOT NULL AUTO_INCREMENT PRIMARY KEY,\r`first_name` VARCHAR(45) NOT NULL,\r`last_name` VARCHAR(45) NOT NULL,\r`email` VARCHAR(100) NOT NULL UNIQUE,\r`phone` VARCHAR(15) NOT NULL,\r`comments` TEXT NOT NULL,\r`status` ENUM(\u0026#39;active\u0026#39;, \u0026#39;inactive\u0026#39;) NOT NULL DEFAULT \u0026#39;active\u0026#39;\r) ENGINE = InnoDB; This command defines the structure of the \u0026ldquo;user\u0026rdquo; table with columns such as \u0026ldquo;id\u0026rdquo;, \u0026ldquo;first_name\u0026rdquo;, \u0026ldquo;last_name\u0026rdquo;, \u0026ldquo;email\u0026rdquo;, \u0026ldquo;phone\u0026rdquo;, \u0026ldquo;comments\u0026rdquo;, and \u0026ldquo;status\u0026rdquo;. These columns represent information about the user, and the \u0026ldquo;id\u0026rdquo; column is set as the auto-incrementing primary key.\nAdd Data to Table \u0026ldquo;user\u0026rdquo; Finally, we can add data to the \u0026ldquo;user\u0026rdquo; table using the INSERT INTO command. Here is an example that adds some records to a table:\nINSERT INTO `user`\r(`first_name`, `last_name`, `email`, `phone`, `comments`, `status`)\rVALUES\r(\u0026#39;Amanda\u0026#39;, \u0026#39;Nunes\u0026#39;, \u0026#39;anunes@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;I love AWS FCJ\u0026#39;, \u0026#39;active\u0026#39;),\r(\u0026#39;Alexander\u0026#39;, \u0026#39;Volkanovski\u0026#39;, \u0026#39;avolkanovski@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;I love AWS FCJ\u0026#39;, \u0026#39;active\u0026#39;),\r(\u0026#39;Khabib\u0026#39;, \u0026#39;Nurmagomedov\u0026#39;, \u0026#39;knurmagomedov@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;I love AWS FCJ\u0026#39;, \u0026#39;active\u0026#39;),\r(\u0026#39;Kamaru\u0026#39;, \u0026#39;Usman\u0026#39;, \u0026#39;kusman@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;I love AWS FCJ\u0026#39;, \u0026#39;active\u0026#39;),\r(\u0026#39;Israel\u0026#39;, \u0026#39;Adesanya\u0026#39;, \u0026#39;iadesanya@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;I love AWS FCJ\u0026#39;, \u0026#39;active\u0026#39;),\r(\u0026#39;Henry\u0026#39;, \u0026#39;Cejudo\u0026#39;, \u0026#39;hcejudo@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;I love AWS FCJ\u0026#39;, \u0026#39;active\u0026#39;),\r(\u0026#39;Valentina\u0026#39;, \u0026#39;Shevchenko\u0026#39;, \u0026#39;vshevchenko@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;I love AWS FCJ\u0026#39;, \u0026#39;active\u0026#39;),\r(\u0026#39;Tyron\u0026#39;, \u0026#39;Woodley\u0026#39;, \u0026#39;twoodley@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;I love AWS FCJ\u0026#39;, \u0026#39;active\u0026#39;),\r(\u0026#39;Rose\u0026#39;, \u0026#39;Namajunas\u0026#39;, \u0026#39;rnamajunas@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;I love AWS FCJ\u0026#39;, \u0026#39;active\u0026#39;),\r(\u0026#39;Tony\u0026#39;, \u0026#39;Ferguson\u0026#39;, \u0026#39;tferguson@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;I love AWS FCJ\u0026#39;, \u0026#39;active\u0026#39;),\r(\u0026#39;Jorge\u0026#39;, \u0026#39;Masvidal\u0026#39;, \u0026#39;jmasvidal@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;I love AWS FCJ\u0026#39;, \u0026#39;active\u0026#39;),\r(\u0026#39;Nate\u0026#39;, \u0026#39;Diaz\u0026#39;, \u0026#39;ndiaz@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;I love AWS FCJ\u0026#39;, \u0026#39;active\u0026#39;),\r(\u0026#39;Conor\u0026#39;, \u0026#39;McGregor\u0026#39;, \u0026#39;cmcGregor@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;I love AWS FCJ\u0026#39;, \u0026#39;active\u0026#39;),\r(\u0026#39;Cris\u0026#39;, \u0026#39;Cyborg\u0026#39;, \u0026#39;ccyborg@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;I love AWS FCJ\u0026#39;, \u0026#39;active\u0026#39;),\r(\u0026#39;Tecia\u0026#39;, \u0026#39;Torres\u0026#39;, \u0026#39;ttorres@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;I love AWS FCJ\u0026#39;, \u0026#39;active\u0026#39;),\r(\u0026#39;Ronda\u0026#39;, \u0026#39;Rousey\u0026#39;, \u0026#39;rrousey@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;I love AWS FCJ\u0026#39;, \u0026#39;active\u0026#39;),\r(\u0026#39;Holly\u0026#39;, \u0026#39;Holm\u0026#39;, \u0026#39;hholm@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;I love AWS FCJ\u0026#39;, \u0026#39;active\u0026#39;),\r(\u0026#39;Joanna\u0026#39;, \u0026#39;Jedrzejczyk\u0026#39;, \u0026#39;jjedrzejczyk@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;I love AWS FCJ\u0026#39;, \u0026#39;active\u0026#39;); This command adds user records to the \u0026ldquo;user\u0026rdquo; table with information such as name, email, phone number, comments, and a default status of \u0026ldquo;active\u0026rdquo;.\nHere\u0026rsquo;s how to create and manage a database and tables in AWS RDS using SQL script.\nsome SQL commands to check database information in a database management system (DBMS) such as MySQL or PostgreSQL: Display a list of all databases: SHOW DATABASES; This command will list all available databases in the system.\nChoose a specific database to work with: USE database_name; This command will move you from your current database to a database named \u0026ldquo;database_name\u0026rdquo;. After using this command, all subsequent SQL commands will apply to this database.\nDisplay tables in the current database: SHOW TABLES; This command will list all the tables present in the current database.\nShows the structure of a specific table: DESCRIBE table_name; This command will tell you the structure of the table named \u0026ldquo;table_name\u0026rdquo;, including the column name, data type, and other column properties.\nDisplay information about database size: SELECT table_schema \u0026#34;Database Name\u0026#34;, SUM(data_length + index_length) / 1024 / 1024 \u0026#34;Database Size (MB)\u0026#34;\rFROM information_schema.tables\rGROUP BY table_schema; This command will display information about the size of the databases in the system, in Megabytes (MB).\nRemember to replace \u0026ldquo;database_name\u0026rdquo; and \u0026ldquo;table_name\u0026rdquo; with the specific names of the database and table you want to test. These commands help you manage and examine information about your database.\nOnce you are in the application directory, run the following command to start the application using npm start:  npm start Check EC2 Instance status: Make sure your EC2 Instance is running and functioning properly.    Test the application in the browser: Open a web browser and enter the IP address or domain name of the EC2 Instance, followed by port 5000 (for example: http://\u0026lt;IP address or domain name\u0026gt; :5000). This will make a connection to your application running on port 5000.\n  Test results: The browser will display your application if everything is configured correctly and the EC2 Instance is working. If not, you need to recheck the previous steps to identify the problem and fix it.\n  http://\u0026lt;IP address or domain name\u0026gt;:5000 Monitoring AWS RDS   On the AWS RDS interface, you can perform the following steps to monitor:\n Select Databases. Choose the DB instance you\u0026rsquo;ve created. Select Monitoring.    To view information about backups of the DB instance in AWS RDS, follow these steps:\n Log in to the AWS Management Console. Select the \u0026ldquo;Amazon RDS\u0026rdquo; service from the list of services. In the RDS dashboard, choose the DB instance you want to check. On the DB instance management page, navigate to the \u0026ldquo;Maintenance \u0026amp; backups\u0026rdquo; tab. Here, you can view information about automatic and manual backups. You can also configure and manage backup settings.    View Snapshot information.\n  Choose the DB snapshot you want to restore.\n In the Actions section, select Restore snapshot.    On the Restore snapshot page, enter a name for the DB instance you want to restore in the DB instance identifier field.\n  Select other settings such as allocated memory size.\n  For more information on each setting, refer to Settings for DB instances.\n  Finally, select Restore DB instance.\n    Complete the restore snapshot process.\n  Check the restored database instance.\n  "
},
{
	"uri": "/6-backup/",
	"title": "Backup and restore",
	"tags": [],
	"description": "",
	"content": "Monitoring AWS RDS - Backup and Restore   On the AWS RDS interface, you can follow these steps to monitor:\n Select Databases. Choose the DB instance you\u0026rsquo;ve created. Click on Monitoring.    To view backup information for a DB instance in AWS RDS, follow these steps:\n Log in to the AWS Management Console. Select the \u0026ldquo;Amazon RDS\u0026rdquo; service from the list of services. In the RDS dashboard, choose the DB instance you want to check. On the DB instance management page, navigate to the \u0026ldquo;Maintenance \u0026amp; backups\u0026rdquo; tab. Here, you can view information about automatic and manual backups. You can also configure and manage backup settings.    View Snapshot Information.\n  Select the DB snapshot you want to restore.\n Under the Actions section, select Restore snapshot.    On the Restore snapshot page, enter a name for the DB instance you want to restore in the DB instance identifier field.\n Choose other settings such as allocated memory size. For more information on each setting, refer to Settings for DB instances. Finally, select Restore DB instance.    Complete the restore snapshot process.\n  Verify that the database instance has been restored.\n  "
},
{
	"uri": "/7-cleanup/",
	"title": "Clean up resources",
	"tags": [],
	"description": "",
	"content": "Resource Cleanup**   To delete the VPC and related resources:\n Delete the DB subnet group. Open the Amazon RDS console. In the navigation pane, select Subnet groups. Choose the DB subnet group related to the lab. Select Delete, then choose Delete in the confirmation window. Delete security groups. Open the Amazon VPC console. Choose VPC Dashboard, then select Security Groups. Select the security group related to the lab. Choose Actions, select Delete security groups, and then choose Delete to confirm. Delete NAT gateway. Open the Amazon VPC console. Choose VPC Dashboard, then select NAT Gateways. Select the NAT Gateway related to the lab. Choose Actions, select Delete NAT gateway. Confirm the deletion and select Delete. Delete the VPC. Open the Amazon VPC console. Choose VPC Dashboard, then select VPC. Select the VPC you want to delete. From Actions, select Delete VPC. On the confirmation page, enter delete and then choose Delete.    Release the Elastic IP addresses\n Open the Amazon EC2 console. Select Amazon EC2 Dashboard, then choose Elastic IPs. Select the Elastic IP address related to the lab. From Actions, select Release Elastic IP addresses. On the confirmation page, choose Release.    Terminate EC2 instance\n Access the EC2 Management Console. In the left navigation bar, select Instances. Select all EC2 Instances related to the lab. Click Actions. Click Manage Instance State. Select Terminate. Click Change State.    Delete DB Instance\n Access the RDS Management Console. In the left navigation bar, select Databases. Select all DB Instances related to the lab. Click Actions. Click Delete. Uncheck Create final snapshot? and acknowledge that automated backups, including system snapshots and point-in-time recovery, will no longer be available. Enter delete me in the empty field. Click Delete.    Delete DB Snapshots\n Access the RDS Management Console. In the left navigation bar, select Snapshots. Select all snapshots related to the lab. Click Actions. Click Delete snapshot. Click Delete.    "
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]